# Awesome-Autonomous-Driving-Security
An awesome &amp; curated list of autonomous driving security papers, including both (physically realizable) attack and defense, especially in the context of adversarial machine learning.
The style is referenced from [Awesome-Binary-Similarity](https://github.com/SystemSecurityStorm/Awesome-Binary-Similarity).


| Title| Venue| Year | Paper| Demo | Code | Remark |            
| :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|Discovering Adversarial Driving Maneuvers against Autonomous Vehicles|USENIX|2023|[link](https://www.usenix.org/conference/usenixsecurity23/presentation/song)|||⚔|
|TPatch: A Triggered Physical Adversarial Patch|USENIX|2023|[link](https://www.usenix.org/conference/usenixsecurity23/presentation/zhu)||[link](https://github.com/forget2save/TPatch)|⚔|
|You Can’t See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks|USENIX|2023|[link](https://www.usenix.org/conference/usenixsecurity23/presentation/cao)|[link](https://github.com/CPSecLab/youcantseeme)||⚔🛡|
|SlowLiDAR: Increasing the Latency of LiDAR-Based Detection Using Adversarial Examples|CVPR|2023|[link](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_SlowLiDAR_Increasing_the_Latency_of_LiDAR-Based_Detection_Using_Adversarial_Examples_CVPR_2023_paper.html)||[link](https://github.com/WUSTL-CSPL/SlowLiDAR)|⚔|
|PLA-LiDAR: Physical Laser Attacks against LiDAR-based 3D Object Detection in Autonomous Vehicle|S&P|2023|[link](https://cyansec.com/files/articles/23Oakland-PLALiDAR.pdf)|[link](https://sites.google.com/view/physical-lidar-attack)||⚔|
|Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving|SenSys|2022|[link](https://www.acsu.buffalo.edu/~yzhu39/Yi_Zhu_homepage_files/papers/SenSys22.pdf)|||⚔|
|AdvDO: Realistic Adversarial Attacks for Trajectory Prediction|ECCV|2022|[link](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650036.pdf)|[link](https://robustav.github.io/RobustPred/)|[link](https://github.com/kikacaty/AdvDO)|⚔|
|Physical Hijacking Attacks against Object Trackers|CCS|2022|[link](https://raymond-muller.netlify.app/publication/physical-hijacking-attacks-against-object-trackers/physical-hijacking-attacks-against-object-trackers.pdf)|[link](https://www.youtube.com/playlist?list=PL1wf-CLdUk8KFhgFAHHfaUaku-8IL3z_h)|[link](https://github.com/purseclab/AttrackZone)|⚔|
|Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving|MM|2022|[link](https://arxiv.org/pdf/2203.00858.pdf)|[link](https://sites.google.com/view/lane-detection-attack/lda)||⚔|
|Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles|USENIX|2022|[link](https://www.usenix.org/conference/usenixsecurity22/presentation/hallyburton)|[link](https://sites.google.com/view/frustum-attack/)|[link](https://gitlab.oit.duke.edu/cpsl/secureperception/frustumattack)|⚔|
|Generating 3D Adversarial Point Clouds under the Principle of LiDARs|AutoSec|2022|[link](https://www.ndss-symposium.org/wp-content/uploads/autosec2022_23026_paper.pdf)|||⚔|
|On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles|CVPR|2022|[link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.html)|[link](https://sites.google.com/view/cav-sec/prediction-adv)|[link](https://github.com/zqzqz/AdvTrajectoryPrediction)|⚔|
|Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems|NDSS|2022|[link](https://www.ndss-symposium.org/wp-content/uploads/2022-130-paper.pdf)|[link](https://seczone.cn/contents/422/1024.html)||⚔|
|Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition|USENIX|2022|[link](https://www.usenix.org/conference/usenixsecurity22/presentation/yan)|[link](https://sites.google.com/view/rollingcolors)||⚔|
|I Can See the Light: Attacks on Autonomous Vehicles Using Invisible Lights|CCS|2021|[link](https://dl.acm.org/doi/10.1145/3460120.3484766)|||⚔|
|Can We Use Arbitrary Objects to Attack LiDAR Perception in Autonomous Driving?|CCS|2021|[link](https://clmiao.github.io/files/papers/CCS2021Can.pdf)|[link](https://www.youtube.com/watch?v=S-QOpFCfgwU)||⚔🛡|
|Adversarial Attacks against LiDAR Semantic Segmentation in Autonomous Driving|SenSys|2021|[link](https://clmiao.github.io/files/papers/CCS2021Can.pdf)|[link](https://www.youtube.com/watch?v=oL84fMPOyzk&t=3s)||⚔|
|Robust Roadside Physical Adversarial Attack Against Deep Learning in Lidar Perception Modules|AsiaCCS|2021|[link](https://dl.acm.org/doi/10.1145/3433210.3453106)|[link](https://sites.google.com/view/roadsideadversary)||⚔🛡|
|They See Me Rollin': Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors|ACSAC|2021|[link](https://arxiv.org/pdf/2101.10011.pdf)||[link](https://github.com/ssloxford/they-see-me-rollin)|⚔🛡|
|Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations|USENIX|2021|[link](https://www.usenix.org/conference/usenixsecurity21/presentation/jing)|||⚔|
|Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack|USENIX|2021|[link](https://www.usenix.org/conference/usenixsecurity21/presentation/sato)|[link](https://sites.google.com/view/cav-sec/drp-attack)|[link](https://github.com/ASGuard-UCI/DRP-attack)|⚔|
|Poltergeist: Acoustic Adversarial Machine Learning against Cameras and Computer Vision|S&P|2021|[link](https://spqrlab1.github.io/papers/ji-poltergeist-oakland21.pdf)|[link](https://sites.google.com/view/poltergeistattack/)|[link](https://github.com/USSLab/PoltergeistAttack)|⚔|
|Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks|S&P|2021|[link](https://arxiv.org/pdf/2106.09249.pdf)|[link](https://sites.google.com/view/cav-sec/msf-adv)|[link](https://github.com/ASGuard-UCI/MSF-ADV)|⚔|
|Exploring Adversarial Robustness of Multi-sensor Perception Systems in Self Driving|CoRL|2021|[link](https://openreview.net/forum?id=m5k1XdK5nI2)|||⚔|
|Fooling LiDAR Perception via Adversarial Trajectory Perturbation|ICCV|2021|[link](https://openaccess.thecvf.com/content/ICCV2021/html/Li_Fooling_LiDAR_Perception_via_Adversarial_Trajectory_Perturbation_ICCV_2021_paper.html)|[link](https://ai4ce.github.io/FLAT/)|[link](https://github.com/ai4ce/FLAT)|⚔|
|Object Removal Attacks on LiDAR-based 3D Object Detectors|AutoSec|2021|[link](https://arxiv.org/abs/2102.03722)|||⚔|
|Who Is in Control? Practical Physical Layer Attack and Defense for mmWave-Based Sensing in Autonomous Vehicles|TIFS|2021|[link](https://engineering.purdue.edu/~lusu/papers/TIFS2021.pdf)|||⚔🛡|
|GhostImage: Remote Perception Domain Attacks against Camera-based Image Classification Systems|RAID|2020|[link](https://www.usenix.org/conference/raid2020/presentation/man)|[link](http://ghostimage.us/)|[link](https://github.com/Harry1993/GhostImage)|⚔|
|Phantom of the ADAS: Securing Advanced Driver-Assistance Systems from Split-Second Phantom Attacks|CCS|2020|[link](https://dl.acm.org/doi/10.1145/3372297.3423359)|[link](https://www.nassiben.com/phantoms)|[link](https://github.com/ymirsky/GhostBusters)|⚔🛡|
|Physically Realizable Adversarial Examples for LiDAR Object Detection|CVPR|2020|[link](https://openaccess.thecvf.com/content_CVPR_2020/html/Tu_Physically_Realizable_Adversarial_Examples_for_LiDAR_Object_Detection_CVPR_2020_paper.html)|||⚔🛡|
|Drift with Devil: Security of Multi-Sensor Fusion based Localization in High-Level Autonomous Driving under GPS Spoofing|USENIX|2020|[link](https://www.usenix.org/conference/usenixsecurity20/presentation/shen)|[link](https://sites.google.com/view/cav-sec/fusionripper)||⚔|
|Towards Robust LiDAR-based Perception in Autonomous Driving: General Black-box Adversarial Sensor Attack and Countermeasures|USENIX|2020|[link](https://www.usenix.org/conference/usenixsecurity20/presentation/sun)|[link](https://sites.google.com/view/cav-sec/adv-lidar-defense)||⚔🛡|
|Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking|ICLR|2020|[link](https://openreview.net/forum?id=rJl31TNYPr)||[link](https://github.com/anonymousjack/hijacking)|⚔|
|Seeing isn't Believing: Towards More Robust Adversarial Attack Against Real World Object Detectors|CCS|2019|[link](https://dl.acm.org/doi/10.1145/3319535.3354259)|[link](https://sites.google.com/view/ai-tricker)||⚔|
|Adversarial Sensor Attack on LiDAR-based Perception in Autonomous Driving|CCS|2019|[link](https://dl.acm.org/doi/10.1145/3319535.3339815)|[link](https://sites.google.com/view/cav-sec/adv-lidar-attack)||⚔|
|Exorcising "Wraith": Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks|USENIX|2023|[link](https://www.usenix.org/conference/usenixsecurity23/presentation/xiao-qifan)|||🛡|
|That Person Behaves Like A Car: Misclassification Attack Detection for Autonomous Systems Using Spatiotemporal Consistency|USENIX|2023|[link](https://www.usenix.org/conference/usenixsecurity23/presentation/man)|||🛡|
|Robust Trajectory Prediction against Adversarial Attacks|CoRL|2022|[link](https://openreview.net/forum?id=uhhA2OryTjj)|[link](https://robustav.github.io/RobustTraj/)|[link](https://github.com/kikacaty/RobustTraj)|🛡|
|Using 3D Shadows to Detect Object Hiding Attacks on Autonomous Vehicle Perception|SafeThings|2022|[link](https://arxiv.org/pdf/2204.13973.pdf)|||🛡|
|Temporal Consistency Checks to Detect LiDAR Spoofing Attacks on Autonomous Vehicle Perception|MAISP|2021|[link](https://arxiv.org/pdf/2106.07833.pdf)|||🛡|
|Shadow-Catcher: Looking Into Shadows to Detect Ghost Objects in Autonomous Vehicle 3D Sensing|ESORICS|2021|[link](https://soteris.github.io/publication/hau-2021-shadowcatcher/hau_esorics21.pdf)|[link](https://sites.google.com/view/shadow-catcher)||🛡|
|“Seeing is not Always Believing”: Detecting Perception Error Attacks Against Autonomous Vehicles|TDSC|2021|[link](https://winser.ece.vt.edu/wp-content/uploads/2021/05/perception_error_attacks_TDSC_smaller_file.pdf)|||🛡|
|Detecting and Identifying Optical Signal Attacks on Autonomous Driving Systems|IOT|2020|[link](https://arxiv.org/pdf/2110.10523.pdf)|||🛡|
